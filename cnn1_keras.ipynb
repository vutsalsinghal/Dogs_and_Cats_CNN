{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and Dogs Classification Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vutsal Singhal\n",
      "last updated: Tue Jun 20 2017 21:15:02 IST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.0.4\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.8.0-54-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "#Metadata\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Vutsal Singhal\"\n",
    "%watermark -u -n -t -z\n",
    "%watermark -p keras\n",
    "%watermark -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cPickle\n",
    "import h5py\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "np.random.seed(7)\n",
    "\n",
    "def image_to_feature_vector(image, size=(28, 28)):\n",
    "\treturn cv2.resize(image, size)\n",
    "\n",
    "data   = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pre-processing images...\n",
      "[INFO] processed 1000/25000\n",
      "[INFO] processed 2000/25000\n",
      "[INFO] processed 3000/25000\n",
      "[INFO] processed 4000/25000\n",
      "[INFO] processed 5000/25000\n",
      "[INFO] processed 6000/25000\n",
      "[INFO] processed 7000/25000\n",
      "[INFO] processed 8000/25000\n",
      "[INFO] processed 9000/25000\n",
      "[INFO] processed 10000/25000\n",
      "[INFO] processed 11000/25000\n",
      "[INFO] processed 12000/25000\n",
      "[INFO] processed 13000/25000\n",
      "[INFO] processed 14000/25000\n",
      "[INFO] processed 15000/25000\n",
      "[INFO] processed 16000/25000\n",
      "[INFO] processed 17000/25000\n",
      "[INFO] processed 18000/25000\n",
      "[INFO] processed 19000/25000\n",
      "[INFO] processed 20000/25000\n",
      "[INFO] processed 21000/25000\n",
      "[INFO] processed 22000/25000\n",
      "[INFO] processed 23000/25000\n",
      "[INFO] processed 24000/25000\n",
      "[INFO] Saving processed images to disk...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] pre-processing images...\")\n",
    "imagePaths = list(paths.list_images('../../../DATASETS/dogs_cats/train'))\n",
    "\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "\timage    = cv2.imread(imagePath)\n",
    "\tlabel    = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\tfeatures = image_to_feature_vector(image)\n",
    "\tdata.append(features)\n",
    "\tlabels.append(label)\n",
    "\n",
    "\tif i > 0 and i % 1000 == 0:\n",
    "\t\tprint(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n",
    "\n",
    "le     = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "data   = np.array(data) / 255.0\n",
    "\n",
    "print('[INFO] Saving processed images to disk...')\n",
    "with h5py.File(\"cnn1_processed_images_and_labels.h5\", \"w\") as hf:\n",
    "\tg = hf.create_group('data_labels')\n",
    "\tg.create_dataset('data', data=data)\n",
    "\tg.create_dataset('labels', data=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed images and labels from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loding processed images and labels from disk...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Loding processed images and labels from disk...')\n",
    "with h5py.File('cnn1_processed_images_and_labels.h5','r') as hf:\n",
    "    g      = hf.get('data_labels')\n",
    "    data   = np.array(g.get('data'))\n",
    "    labels = np.array(g.get('labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train/test spilts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] constructing training/testing split...\")\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test  = np.array(X_test)\n",
    "y_test  = np.array(y_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, 28, 28).astype('float32')\n",
    "X_test  = X_test.reshape(X_test.shape[0], 3, 28, 28).astype('float32')\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved models and weights from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loding saved model from disk...\n",
      "[INFO] Loding saved weights from disk...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Loding saved model from disk...')\n",
    "model = load_model('cnn1_dogs_cats_model.h5')\n",
    "print('[INFO] Loding saved weights from disk...')\n",
    "model.load_weights('cnn1_dogs_cats_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, padding='valid', kernel_size=(3, 3), data_format='channels_first', input_shape=(3, 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0476 - acc: 0.9820 - val_loss: 1.3515 - val_acc: 0.6788\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0505 - acc: 0.9811 - val_loss: 1.4308 - val_acc: 0.6780\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0570 - acc: 0.9790 - val_loss: 1.3515 - val_acc: 0.6866\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0461 - acc: 0.9822 - val_loss: 1.3975 - val_acc: 0.6768\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 13s - loss: 0.0508 - acc: 0.9810 - val_loss: 1.3827 - val_acc: 0.6772\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0513 - acc: 0.9808 - val_loss: 1.2618 - val_acc: 0.6720\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0522 - acc: 0.9807 - val_loss: 1.3293 - val_acc: 0.6752\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0511 - acc: 0.9816 - val_loss: 1.3398 - val_acc: 0.6816\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0449 - acc: 0.9838 - val_loss: 1.3581 - val_acc: 0.6788\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0454 - acc: 0.9837 - val_loss: 1.4469 - val_acc: 0.6794\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0463 - acc: 0.9836 - val_loss: 1.4711 - val_acc: 0.6822\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0482 - acc: 0.9840 - val_loss: 1.3597 - val_acc: 0.6774\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0427 - acc: 0.9843 - val_loss: 1.3690 - val_acc: 0.6840\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0457 - acc: 0.9837 - val_loss: 1.3768 - val_acc: 0.6840\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0459 - acc: 0.9831 - val_loss: 1.3824 - val_acc: 0.6860\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0411 - acc: 0.9856 - val_loss: 1.3776 - val_acc: 0.6856\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 13s - loss: 0.0379 - acc: 0.9860 - val_loss: 1.4117 - val_acc: 0.6710\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0451 - acc: 0.9842 - val_loss: 1.3596 - val_acc: 0.6800\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0359 - acc: 0.9881 - val_loss: 1.4279 - val_acc: 0.6766\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0461 - acc: 0.9838 - val_loss: 1.4041 - val_acc: 0.6842\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0372 - acc: 0.9868 - val_loss: 1.4055 - val_acc: 0.6782\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0428 - acc: 0.9842 - val_loss: 1.4301 - val_acc: 0.6824\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0362 - acc: 0.9870 - val_loss: 1.5476 - val_acc: 0.6766\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0372 - acc: 0.9864 - val_loss: 1.3835 - val_acc: 0.6762\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 17s - loss: 0.0338 - acc: 0.9877 - val_loss: 1.4550 - val_acc: 0.6842\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0348 - acc: 0.9879 - val_loss: 1.5231 - val_acc: 0.6852\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0361 - acc: 0.9876 - val_loss: 1.4067 - val_acc: 0.6812\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0356 - acc: 0.9875 - val_loss: 1.3752 - val_acc: 0.6752\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0364 - acc: 0.9867 - val_loss: 1.4760 - val_acc: 0.6860\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0377 - acc: 0.9871 - val_loss: 1.4288 - val_acc: 0.6806\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0358 - acc: 0.9875 - val_loss: 1.4253 - val_acc: 0.6856\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0248 - acc: 0.9917 - val_loss: 1.4913 - val_acc: 0.6742\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0297 - acc: 0.9900 - val_loss: 1.4569 - val_acc: 0.6868\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0313 - acc: 0.9887 - val_loss: 1.5107 - val_acc: 0.6844\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0318 - acc: 0.9887 - val_loss: 1.5162 - val_acc: 0.6744\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0308 - acc: 0.9891 - val_loss: 1.4323 - val_acc: 0.6778\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0340 - acc: 0.9885 - val_loss: 1.5511 - val_acc: 0.6766\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 14s - loss: 0.0315 - acc: 0.9896 - val_loss: 1.4829 - val_acc: 0.6766\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0311 - acc: 0.9888 - val_loss: 1.5088 - val_acc: 0.6782\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0288 - acc: 0.9899 - val_loss: 1.5382 - val_acc: 0.6768\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0293 - acc: 0.9901 - val_loss: 1.4902 - val_acc: 0.6840\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0279 - acc: 0.9909 - val_loss: 1.4625 - val_acc: 0.6808\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0315 - acc: 0.9891 - val_loss: 1.4644 - val_acc: 0.6842\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0317 - acc: 0.9884 - val_loss: 1.4826 - val_acc: 0.6822\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0308 - acc: 0.9889 - val_loss: 1.5042 - val_acc: 0.6782\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0318 - acc: 0.9889 - val_loss: 1.4572 - val_acc: 0.6848\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0279 - acc: 0.9909 - val_loss: 1.4621 - val_acc: 0.6834\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 16s - loss: 0.0229 - acc: 0.9915 - val_loss: 1.5144 - val_acc: 0.6810\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0226 - acc: 0.9921 - val_loss: 1.5451 - val_acc: 0.6794\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 15s - loss: 0.0282 - acc: 0.9905 - val_loss: 1.5008 - val_acc: 0.6820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a3c519e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating the model on test data...\n",
      "4700/5000 [===========================>..] - ETA: 0s\n",
      "Accuracy: 68.2000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Evaluating the model on test data...')\n",
    "scores = model.evaluate(X_test, y_test, batch_size=100, verbose=1)\n",
    "print(\"\\nAccuracy: %.4f%%\\n\"%(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model and weights to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving compiled model and weights to disk...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Saving compiled model and weights to disk...')\n",
    "model.save('cnn1_dogs_cats_model.h5')\n",
    "model.save_weights('cnn1_dogs_cats_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Plotting model...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Plotting model...')\n",
    "plot_model(model, to_file='cnn1_keras_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting images...\n",
      "Enter 0 < number < 12500: 2351\n",
      "[INFO] predicting new image: ../../../DATASETS/dogs_cats/test/2351.jpg\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "Probablities: [  7.53419013e-22   1.00000000e+00]\n",
      "Class: [1]\n",
      "Continue:(y/n) y\n",
      "Enter 0 < number < 12500: 125000\n",
      "Number not within the range!\n",
      "Continue:(y/n) y\n",
      "Enter 0 < number < 12500: 3468\n",
      "[INFO] predicting new image: ../../../DATASETS/dogs_cats/test/3468.jpg\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "Probablities: [ 0.  1.]\n",
      "Class: [1]\n",
      "Continue:(y/n) n\n",
      "Exit initiated...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Predicting images...')\n",
    "cont = 'y'\n",
    "while(True):\n",
    "    if cont == 'n':\n",
    "        print('Exit initiated...')\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    inp = int(raw_input('Enter 0 < number < 12500: '))\n",
    "    if inp >= 0 and inp < 12501:\n",
    "        path  = '../../../DATASETS/dogs_cats/test/%s.jpg'%(inp)\n",
    "        image = cv2.imread(path)\n",
    "        feature = image_to_feature_vector(image)\n",
    "        feature = np.reshape(feature,(1,3,28,28))\n",
    "\n",
    "        print(\"[INFO] predicting new image: %s\")%(path)\n",
    "        prediction = model.predict(feature, batch_size=1, verbose=1)[0]\n",
    "        classes    = model.predict_classes(feature, verbose=1)\n",
    "        print('Probablities: %s')%(prediction)\n",
    "        print('Class: %s')%(classes)\n",
    "\n",
    "        if prediction[0] == 1:\n",
    "            animal = 'Predicted [cat]'\n",
    "        else:\n",
    "            animal = 'Predicted: [dog]'\n",
    "\n",
    "        cv2.putText(image, animal, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.namedWindow('cat/dog', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('cat/dog', image)\n",
    "        if cv2.waitKey(0):\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print 'Number not within the range!'\n",
    "    \n",
    "    cont = str(raw_input('Continue:(y/n) '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
